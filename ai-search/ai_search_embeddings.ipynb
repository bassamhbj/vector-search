{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search: Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "aoai_endpoint = os.getenv('AOAI_ENDPOINT')\n",
    "aoai_api_key = os.getenv('AOAI_API_KEY')\n",
    "aoai_api_version = os.getenv('API_VERSION')\n",
    "aoai_deployment = os.getenv('DEPLOYMENT_NAME')\n",
    "\n",
    "ai_search_endpoint = os.getenv('AI_SEARCH_ENDPOINT')\n",
    "ai_search_key = os.getenv('AI_SEARCH_KEY')\n",
    "ai_search_index_name = os.getenv('AI_SEARCH_INDEX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_client = SearchClient(\n",
    "  endpoint=ai_search_endpoint,\n",
    "  index_name=ai_search_index_name,\n",
    "  credential=AzureKeyCredential(ai_search_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_deployment=aoai_deployment,\n",
    "  api_version=aoai_api_version,\n",
    "  azure_endpoint=aoai_endpoint,\n",
    "  api_key=aoai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "\n",
    "with open(\"../data/what_is_ai_studio.md\", \"r\") as file:\n",
    "  from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "  text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "  pages = text_splitter.split_text(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "documents = []\n",
    "\n",
    "for item in pages:\n",
    "  doc = {\n",
    "    \"id\": str(uuid.uuid4()),\n",
    "    \"content\": item,\n",
    "    \"content_vector\": client.embeddings.create(input=item, model=aoai_deployment).data[0].embedding\n",
    "  }\n",
    "  documents.append(doc)\n",
    "\n",
    "result = search_client.upload_documents(documents=documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
